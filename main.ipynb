{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTENT-BASED FILTERING\n",
    "\n",
    "Here we are using cosine similarity which measures the cosine of the angle between two vectors. In this case, the vectors are the one-hot encoded genre data for the movies. The cosine similarity is a measure of how similar two movies are based on their genre. Scikit learn's cosine similarity package is used here to do content-based filtering. In the code snippet below, we are taking into consideration, the genre of the movie primarily that is given in ml-25m/movie.csv file. We are then, also grouping the recommendations based on their ratings to decide what the top 10 recommendations should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4780                Monsters, Inc. (2001)\n",
      "3021                   Toy Story 2 (1999)\n",
      "43614                        Moana (2016)\n",
      "3912     Emperor's New Groove, The (2000)\n",
      "2203                          Antz (1998)\n",
      "22353               Boxtrolls, The (2014)\n",
      "30348            The Good Dinosaur (2015)\n",
      "11604              Shrek the Third (2007)\n",
      "20015                        Turbo (2013)\n",
      "12969      Tale of Despereaux, The (2008)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load the movies data\n",
    "movies = pd.read_csv('ml-25m/movies.csv')\n",
    "\n",
    "# One-hot encoding for genres\n",
    "movies['genres'] = movies['genres'].apply(lambda x: x.split('|'))\n",
    "genres_encoded = movies['genres'].str.join('|').str.get_dummies()\n",
    "\n",
    "# Combine the encoded genres with the original movies dataframe\n",
    "movies_encoded = pd.concat([movies, genres_encoded], axis=1)\n",
    "\n",
    "# Load the ratings data\n",
    "ratings = pd.read_csv('ml-25m/ratings.csv')\n",
    "\n",
    "# Calculate the mean rating for each movie\n",
    "mean_ratings = ratings.groupby('movieId')['rating'].mean()\n",
    "\n",
    "# Calculate the number of ratings for each movie\n",
    "num_ratings = ratings.groupby('movieId')['rating'].count()\n",
    "\n",
    "# Calculate the weighted rating for each movie\n",
    "weighted_ratings = (mean_ratings * num_ratings) / (num_ratings + 100)  # Adding 100 as a arbitrary constant to reduce the effect of movies with very few ratings\n",
    "\n",
    "# Add the weighted ratings to the movies dataframe\n",
    "movies_encoded = movies_encoded.merge(weighted_ratings.rename('weighted_rating'), how='left', on='movieId')\n",
    "\n",
    "# Fill NA values with the mean of the weighted ratings\n",
    "movies_encoded['weighted_rating'] = movies_encoded['weighted_rating'].fillna(movies_encoded['weighted_rating'].mean())\n",
    "\n",
    "# Create a reverse map of indices and movie titles\n",
    "indices = pd.Series(movies_encoded.index, index=movies_encoded['title']).drop_duplicates()\n",
    "\n",
    "def get_recommendations(title, num_recommendations=10):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "    \n",
    "    # Get the genre data for this movie\n",
    "    movie_genres = movies_encoded.iloc[idx, 3:-1].values.reshape(1, -1)  # Exclude the last column, which is now the weighted rating\n",
    "\n",
    "    # Calculate similarity scores between this movie and all others\n",
    "    similarity_scores = {}\n",
    "    for i, row in movies_encoded.iterrows():\n",
    "        if i != idx:  # don't compare the movie with itself\n",
    "            other_movie_genres = row.iloc[3:-1].values.reshape(1, -1)  # Exclude the last column, which is now the weighted rating\n",
    "            similarity_scores[i] = cosine_similarity(movie_genres, other_movie_genres)[0][0]\n",
    "    \n",
    "    # Sort movies based on the similarity scores and the weighted ratings\n",
    "    sorted_similarity_scores = sorted(similarity_scores.items(), key=lambda x: (x[1], movies_encoded.loc[x[0], 'weighted_rating']), reverse=True)\n",
    "    \n",
    "    # Get the indices of the top matches\n",
    "    top_indices = [index for index, score in sorted_similarity_scores[:num_recommendations]]\n",
    "    \n",
    "    # Return the top matches\n",
    "    return movies_encoded['title'].iloc[top_indices]\n",
    "\n",
    "# Test the function\n",
    "print(get_recommendations('Toy Story (1995)'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fuzzywuzzy\n",
    "%pip install flask_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rimikadhara/Library/Python/3.10/lib/python/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I can recommend movies for you.\n",
      "Enter 'quit' to exit the chatbot at any time.\n",
      "If you liked King Cobra (2016), you might also like these movies:\n",
      "1. Shawshank Redemption, The (1994)\n",
      "2. Godfather, The (1972)\n",
      "3. Godfather: Part II, The (1974)\n",
      "4. Goodfellas (1990)\n",
      "5. American History X (1998)\n",
      "6. On the Waterfront (1954)\n",
      "7. Green Mile, The (1999)\n",
      "8. No Country for Old Men (2007)\n",
      "9. 400 Blows, The (Les quatre cents coups) (1959)\n",
      "10. Dog Day Afternoon (1975)\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "def chatbot():\n",
    "    print(\"Hello! I can recommend movies for you.\")\n",
    "    print(\"Enter 'quit' to exit the chatbot at any time.\")\n",
    "    while True:\n",
    "        title = input(\"Enter a movie title: \")\n",
    "        if title.lower() == 'quit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        # Use fuzzy matching to find the closest match to the user's input in the list of movie titles\n",
    "        closest_match, score = process.extractOne(title, movies_encoded['title'].values)\n",
    "        if score < 60:  # You can adjust this threshold\n",
    "            print(\"I'm sorry, but I couldn't find a movie that closely matches '{}'. Please try another one.\".format(title))\n",
    "            continue\n",
    "        try:\n",
    "            recommendations = get_recommendations(closest_match)\n",
    "            print(\"If you liked {}, you might also like these movies:\".format(closest_match))\n",
    "            for i, movie in enumerate(recommendations, 1):\n",
    "                print(\"{}. {}\".format(i, movie))\n",
    "        except KeyError:\n",
    "            print(\"I'm sorry, but I couldn't find that movie in my database. Please try another one.\")\n",
    "\n",
    "# Run the chatbot\n",
    "chatbot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLLABORATIVE FILTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering using SVD\n",
    "\n",
    "Here's a high-level overview of what we're doing:\n",
    "\n",
    "1. Preprocess our data to get a user-item matrix. Each cell in this matrix represents the rating a user gave to a movie. If a user hasn't rated a movie, we'll leave that cell empty for now.\n",
    "2. Apply SVD to this matrix. SVD will decompose our user-item matrix into three separate matrices. We can use these matrices to predict the missing ratings in our user-item matrix.\n",
    "3. Write a function that uses these predicted ratings to recommend movies to a user.\n",
    "\n",
    "How we are using Singular Value Decomposition:\n",
    "- The SVD model decomposes the user-item matrix (which has users as rows, movies as columns, and user ratings as cell values) into three separate matrices.\n",
    "- These matrices capture the underlying patterns in the ratings data. In other words, they capture the latent factors that explain the observed user ratings. For example, these latent factors might represent different genres, time periods, or other movie characteristics that affect how users rate movies. Once the matrix is factorized, you multiply the three matrices to create a new matrix that represents predicted ratings for all user-movie pairs, including those movies that a user hasn't rated yet. This is a form of collaborative filtering because it uses the ratings of all users to predict the ratings of individual users. The predicted ratings are then used to recommend movies to a user.\n",
    "- By multiplying these matrices together, we can predict what rating a user would give to a movie, even if they haven't rated it yet.\n",
    "To recommend movies to a user, the system sorts the movies by their predicted ratings and picks the top ones. Because we're excluding movies that the user has already rated, these will be new movie recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data to get a user-item matrix\n",
    "# Limit data to the top 1000 users and top 1000 movies for the purpose of this demonstration\n",
    "top_users = ratings['userId'].value_counts().index[:1000]\n",
    "top_movies = ratings['movieId'].value_counts().index[:1000]\n",
    "limited_ratings = ratings[ratings['userId'].isin(top_users) & ratings['movieId'].isin(top_movies)]\n",
    "\n",
    "# Create the user-item matrix\n",
    "user_item_matrix = limited_ratings.pivot_table(index='userId', columns='movieId', values='rating', fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U: (1000, 50)\n",
      "Shape of sigma: (50, 50)\n",
      "Shape of Vt: (50, 1000)\n",
      "                                               title  movieId\n",
      "0                                The Revenant (2015)   139385\n",
      "1                                    Deadpool (2016)   122904\n",
      "2                                     Ant-Man (2015)   122900\n",
      "3                                 The Martian (2015)   134130\n",
      "4                              Big Short, The (2015)   148626\n",
      "5  Star Wars: Episode VII - The Force Awakens (2015)   122886\n",
      "6                                   Cape Fear (1991)     1343\n",
      "7                  Captain America: Civil War (2016)   122920\n",
      "8             Snow White and the Seven Dwarfs (1937)      594\n",
      "9                                    Whiplash (2014)   112552\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Convert the user-item matrix to a numpy array\n",
    "user_item_matrix_np = user_item_matrix.to_numpy()\n",
    "\n",
    "\"\"\"Apply SVD -- The SVD model predicts ratings for all movies, including those that the user has already rated. \n",
    "    Therefore, if a user has rated a movie highly, it's likely that the model will predict a high rating for that \n",
    "    movie and potentially recommend it back to the user. We will exclude those movies in the function later.\"\"\"\n",
    "U, sigma, Vt = svds(user_item_matrix_np, k=50)\n",
    "\n",
    "# Since we got sigma as an array, we need to convert it to a diagonal matrix form.\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Preview the shapes of U, sigma, and Vt\n",
    "print(f\"Shape of U: {U.shape}\")\n",
    "print(f\"Shape of sigma: {sigma.shape}\")\n",
    "print(f\"Shape of Vt: {Vt.shape}\")\n",
    "\n",
    "\n",
    "# Predict the ratings\n",
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "\n",
    "# Convert the predicted ratings to a DataFrame\n",
    "predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=user_item_matrix.columns, index=user_item_matrix.index)\n",
    "\n",
    "def recommend_movies(user_id, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    This function receives a user ID and returns a list of recommended movies. \n",
    "    Recommendations are based on the predicted ratings.\n",
    "    \"\"\"\n",
    "    # Get the predicted ratings for this user\n",
    "    user_ratings = predicted_ratings_df.loc[user_id]\n",
    "    \n",
    "    # Get the movies that the user has already rated\n",
    "    rated_movies = ratings[ratings['userId'] == user_id]['movieId']\n",
    "    \n",
    "    # Exclude the movies that the user has already rated\n",
    "    user_ratings = user_ratings.drop(rated_movies, errors='ignore')\n",
    "    \n",
    "    # Sort the movies based on the predicted ratings\n",
    "    sorted_user_ratings = user_ratings.sort_values(ascending=False)\n",
    "    \n",
    "    # Get the top recommendations\n",
    "    recommendations = sorted_user_ratings[:num_recommendations]\n",
    "    \n",
    "    # Map the movie IDs to titles\n",
    "    recommendations = recommendations.reset_index()\n",
    "    recommendations = recommendations.merge(movies[['movieId', 'title']], how='left', on='movieId')\n",
    "    \n",
    "    # Return the top recommendations\n",
    "    return recommendations[['title', 'movieId']]\n",
    "\n",
    "print(recommend_movies(548))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering with PCA\n",
    "\n",
    "The PCA method involves transforming your user-item matrix to a lower-dimensional space using PCA, and then computing cosine similarity between users. The cosine similarity is used to find users that are most similar to the given user. The movies that these similar users have rated highly but the given user hasn't watched yet are recommended to the given user. This is a form of collaborative filtering because it uses the preferences of similar users to recommend movies to a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Center the data\n",
    "centered_matrix = user_item_matrix - user_item_matrix.mean()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(centered_matrix)\n",
    "\n",
    "# Transform the original data\n",
    "transformed_matrix = pca.transform(centered_matrix)\n",
    "\n",
    "# Convert the transformed matrix to a DataFrame\n",
    "transformed_df = pd.DataFrame(transformed_matrix, index=user_item_matrix.index)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate the cosine similarity between users\n",
    "user_similarity = cosine_similarity(transformed_df)\n",
    "\n",
    "# Convert the similarity matrix to a DataFrame\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                           title\n",
      "0   134130              The Martian (2015)\n",
      "1   148626           Big Short, The (2015)\n",
      "2   158238            The Nice Guys (2016)\n",
      "3   139644                  Sicario (2015)\n",
      "4   139385             The Revenant (2015)\n",
      "5   128360        The Hateful Eight (2015)\n",
      "6   122904                 Deadpool (2016)\n",
      "7   161024  Jim Jefferies: Freedumb (2016)\n",
      "8   122900                  Ant-Man (2015)\n",
      "9   117121            Dorothy Mills (2008)\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies_pca(user_id, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    This function receives a user ID and returns a list of recommended movies. \n",
    "    Recommendations are based on the ratings of similar users.\n",
    "    \"\"\"\n",
    "    # Get the top 10 similar users to the given user\n",
    "    similar_users = user_similarity_df[user_id].sort_values(ascending=False)[1:11]\n",
    "    \n",
    "    # Get the movies that these similar users have rated highly\n",
    "    high_rated_movies_similar_users = ratings[ratings['userId'].isin(similar_users.index) & (ratings['rating'] >= 4)]\n",
    "    \n",
    "    # Exclude the movies that the user has already rated\n",
    "    rated_movies = ratings[ratings['userId'] == user_id]['movieId']\n",
    "    recommended_movies = high_rated_movies_similar_users.loc[~high_rated_movies_similar_users['movieId'].isin(rated_movies)]\n",
    "    \n",
    "    # Get the top recommendations\n",
    "    recommendations = recommended_movies['movieId'].value_counts().index[:num_recommendations]\n",
    "    \n",
    "    # Map the movie IDs to titles\n",
    "    recommendations = pd.DataFrame(recommendations, columns=['movieId'])\n",
    "    recommendations = recommendations.merge(movies[['movieId', 'title']], how='left', on='movieId')\n",
    "    \n",
    "    # Return the top recommendations\n",
    "    return recommendations\n",
    "\n",
    "# Test the function\n",
    "print(recommend_movies_pca(548))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary for Collaborative Filtering\n",
    "\n",
    "recommend_movies: This function uses a method called collaborative filtering via singular value decomposition (SVD). It first predicts ratings for all movies a user hasn't rated yet, based on their existing ratings and the ratings of all other users. It then recommends the movies with the highest predicted ratings. The underlying assumption is that users who have agreed in the past will agree in the future, and that they will like similar kind of movies.\n",
    "\n",
    "recommend_movies_pca: This function also uses collaborative filtering, but via a different approach called k-nearest neighbors (k-NN) using PCA for dimensionality reduction. It first identifies the users that are most similar to the given user, based on their ratings of all movies. It then recommends the movies that these similar users have rated highly but the given user hasn't watched yet. The underlying assumption is that users who are similar (based on their ratings) will have similar preferences for unrated movies.\n",
    "\n",
    "In summary, recommend_movies (SVD) generates recommendations based on a combination of the given user's ratings and all other users' ratings, while recommend_movies_pca (PCA) generates recommendations based on the ratings of users who are similar to the given user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small-Scale Implementation of Matrix Factorization\n",
    "\n",
    "This Matrix Factorization simply aims to implement a simple form of matrix factorization for collaborative filtering, often used in recommender systems. At a high-level, it reads a csv file with ratings and tries to fill in the missing ratings\n",
    "\n",
    "Here's a summary of what the code does:\n",
    "\n",
    "csv_to_mtx: This function reads a CSV file and converts it to a NumPy array. This file is assumed to be a user-item matrix with ratings, where each row represents a user, each column represents an item (movie), and the cell values are the user's rating for that item.\n",
    "\n",
    "matrix_factorization: This function performs matrix factorization on the input user-item matrix R using stochastic gradient descent. The function takes two initial matrices P and Q which are the latent feature matrices for the users and items respectively, a parameter K which is the number of latent features, and additional parameters to control the learning process: steps for the number of iterations to run, alpha for the learning rate, and beta for the regularization term. The function iteratively updates P and Q to minimize the difference between the actual ratings and the predicted ratings (the dot product of P and Q), plus a regularization term to prevent overfitting. If the error falls below 0.001, the function stops early.\n",
    "\n",
    "After defining these functions, the script reads a user-item matrix from a CSV file using the csv_to_mtx function. It then initializes the user and item latent feature matrices P and Q with random values. These matrices have dimensions N x K and M x K respectively, where N is the number of users, M is the number of items, and K is the number of latent features.\n",
    "\n",
    "The script then calls the matrix_factorization function to factorize the user-item matrix into P and Q. The resulting matrices represent the users and items in terms of the latent feature space.\n",
    "\n",
    "Finally, the script calculates the predicted ratings by taking the dot product of P and Q. This resulting matrix nR has the same dimensions as the original user-item matrix, but the ratings are now predictions based on the learned latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 3. 0. 1.]\n",
      " [4. 0. 0. 1.]\n",
      " [1. 1. 0. 5.]\n",
      " [1. 0. 0. 4.]\n",
      " [0. 1. 5. 4.]\n",
      " [2. 1. 3. 0.]]\n",
      "\n",
      "Predictions:\n",
      "[[5.01036269 2.92309956 3.7599997  1.00322818]\n",
      " [3.97408237 2.41286203 2.68993508 0.99988375]\n",
      " [1.04952349 0.91155024 5.04139756 4.97017238]\n",
      " [0.99089893 0.72014583 3.96034546 3.97950694]\n",
      " [1.75164628 1.0417902  4.96814036 4.0010332 ]\n",
      " [1.8940461  1.15572328 2.99266344 1.84698784]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def csv_to_mtx(file):\n",
    "    mtx = numpy.genfromtxt('ml-25m/user-movie-ratings.csv', delimiter=',', skip_header=1,)\n",
    "    mtx = numpy.array(mtx)\n",
    "    return mtx\n",
    "\n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    '''\n",
    "    R: rating matrix\n",
    "    P: |U| * K (User features matrix)\n",
    "    Q: |D| * K (Item features matrix)\n",
    "    K: latent features\n",
    "    steps: iterations\n",
    "    alpha: learning rate\n",
    "    beta: regularization parameter'''\n",
    "    Q = Q.T\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    # calculate error\n",
    "                    eij = R[i][j] - numpy.dot(P[i,:],Q[:,j])\n",
    "\n",
    "                    for k in range(K):\n",
    "                        # calculate gradient with a and beta parameter\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "\n",
    "        eR = numpy.dot(P,Q)\n",
    "\n",
    "        e = 0\n",
    "\n",
    "        for i in range(len(R)):\n",
    "\n",
    "            for j in range(len(R[i])):\n",
    "\n",
    "                if R[i][j] > 0:\n",
    "\n",
    "                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)\n",
    "\n",
    "                    for k in range(K):\n",
    "\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        # 0.001: local minimum\n",
    "        if e < 0.001:\n",
    "\n",
    "            break\n",
    "\n",
    "    return P, Q.T\n",
    "\n",
    "R = csv_to_mtx('ml-25m/user-movie-ratings.csv')\n",
    "print(R)\n",
    "# N: num of User\n",
    "N = len(R)\n",
    "# M: num of Movie\n",
    "M = len(R[0])\n",
    "# Num of Features\n",
    "K = 5\n",
    "\n",
    "P = numpy.random.rand(N,K)\n",
    "Q = numpy.random.rand(M,K)\n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "\n",
    "nR = numpy.dot(nP, nQ.T)\n",
    "print()\n",
    "print(\"Predictions:\")\n",
    "print(nR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
